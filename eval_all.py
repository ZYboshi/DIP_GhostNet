import json
import torch
import torchvision.transforms as transforms
from PIL import Image
import os
import csv

import args
import models
from utils.model_metrics  import calculate_model_complexity, measure_inference_speed, get_memory_usage, calculate_accuracy_metrics

#è¿”å›åˆ†ç±»ç»“æœ
def predict_single_image(model, image_path):
    try:
        # åŠ è½½å›¾ç‰‡
        image = Image.open(image_path).convert('RGB')
        # å®šä¹‰æ•°æ®é¢„å¤„ç†å˜æ¢
        transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],   # å½’ä¸€åŒ–
                                std=[0.229, 0.224, 0.225])
        ])
        input_tensor = transform(image).unsqueeze(0)
        # å°†è¾“å…¥å¼ é‡ç§»å…¥GPU
        input_tensor = input_tensor.to(device)

        # è¿›è¡Œæ¨ç†
        with torch.no_grad():
            output = model(input_tensor)

        # è·å–é¢„æµ‹ç»“æœ
        probabilities = torch.nn.functional.softmax(output, dim=1)[0]
        predicted_class = torch.argmax(probabilities).item()
        print(f"é¢„æµ‹çš„ç±»åˆ«ç´¢å¼•: {predicted_class}")
        print(f"æœ€å¤§æ¦‚ç‡: {probabilities[predicted_class]:.4f}")
        return predicted_class, probabilities[predicted_class].item()


    except Exception as e:
        print(f"Error predicting image: {e}")
        return None, None

def load_model(model_name):
    supported_models = ['ghostnet_100','ghostnet_130','mobilenetv3_small','mobilenetv3_large']

    try:
        if model_name not in supported_models:
            raise ValueError('Model not supported')
        model = models.get_model(model_name=model_name, pretrained=True, num_classes=args.num_classes)
        model = model.to(device)
        model.eval()
        return model
    except ValueError as e:
        print(e)
        exit(1)
# è·å¾—æ˜ å°„è¡¨
def load_classes_mapping(json_file = args.json_path):
    with open(json_file,'r') as file:
        class_mapping = json.load(file)

    # åˆ›å»ºä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºæ–‡ä»¶åï¼Œå€¼ä¸ºç±»åˆ«ç¼–å·
    file_to_class = {v[0]: k for k, v in class_mapping.items()}
    return file_to_class


# åœ¨ import éƒ¨åˆ†ä¹‹åæ·»åŠ 
def analyze_model_metrics(model, model_name):
    """
    åˆ†ææ¨¡å‹æ€§èƒ½æŒ‡æ ‡ï¼ˆä¸ä¿®æ”¹åŸæœ‰é€»è¾‘ï¼‰
    """
    print(f"\nğŸ“Š å¼€å§‹åˆ†æ {model_name} æ¨¡å‹å¤æ‚åº¦...")

    # 1. è®¡ç®—æ¨¡å‹å¤æ‚åº¦
    params_m, flops_g = calculate_model_complexity(model)
    print(f"  â†’ å‚æ•°é‡: {params_m:.2f}M")
    print(f"  â†’ FLOPs: {flops_g:.2f}G")

    # 2. æµ‹é‡æ¨ç†é€Ÿåº¦
    avg_time_ms, throughput_imgs = measure_inference_speed(model)
    print(f"  â†’ å¹³å‡æ¨ç†æ—¶é—´: {avg_time_ms:.2f}ms")
    print(f"  â†’ ååé‡: {throughput_imgs:.2f} img/s")

    # 3. è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ
    memory_mb = get_memory_usage()
    print(f"  â†’ å†…å­˜ä½¿ç”¨: {memory_mb:.2f}MB")

    return {
        'params_m': params_m,
        'flops_g': flops_g,
    }




#å°†é¢„æµ‹ç»“æœä»¥åŠ
def main(model_name, output_csv='predictions.csv'):
    model = load_model(model_name)
    print('åŠ è½½æ¨¡å‹æˆåŠŸ')

    # === æ–°å¢ï¼šåœ¨å¼€å§‹é¢„æµ‹å‰åˆ†ææ¨¡å‹æŒ‡æ ‡ ===
    metrics = analyze_model_metrics(model, model_name)

    file_to_class = load_classes_mapping()

    #å­˜å‚¨image_pathäºå­—å…¸ä¸­ï¼Œæ–¹ä¾¿åç»­å¯»æ‰¾
    image_data = {}
    image_dir = os.path.join('dataset','ImageNet-Mini','images')
    for image_folder in os.listdir(image_dir):
        folder_path = os.path.join(image_dir,image_folder)
        image_data[image_folder] = []
        for image_file in os.listdir(folder_path):
            image_path = os.path.join(folder_path,image_file)
            image_data[image_folder].append(image_path)

    results = []
    for image_folder,image_paths in image_data.items():
        #éå†æ¯ä¸ªå›¾ç‰‡ç›®å½•
        for image_path in image_paths:
            predicted_class, probability = predict_single_image(model, image_path)
            if predicted_class is not None:
                actual_class = int(file_to_class.get(image_folder, -1))  # è·å–å®é™…ç±»åˆ«ç¼–å·
                results.append({
                    'image_path': image_path,
                    'folder_name': image_folder,
                    'predicted_class': predicted_class,
                    'probability': probability,
                    'actual_class': actual_class
                })

    # å†™å…¥CSVæ–‡ä»¶
    with open(output_csv, mode='w', newline='') as file:
        fieldnames = ['image_path', 'folder_name', 'predicted_class', 'probability', 'actual_class']
        writer = csv.DictWriter(file, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(results)

if __name__ == "__main__":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model_name = 'ghostnet_100'
    output_csv = './result/predictions_ghostnet.csv'
    main(model_name=model_name, output_csv=output_csv)
    model_name = 'mobilenetv3_small'
    output_csv = './result/mobilenetv3_small.csv'
    main(model_name=model_name, output_csv=output_csv)